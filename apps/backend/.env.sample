SESSION_SECRET_KEY="a-secret-key"
SYNC_DATABASE_URL="sqlite:///./app.db"
ASYNC_DATABASE_URL="sqlite+aiosqlite:///./app.db"
PYTHONDONTWRITEBYTECODE=1

# =============================================================================
# LLM CONFIGURATION
# =============================================================================
# The LLM provider handles CV/job parsing and improvement suggestions.
# Supported providers: openai | anthropic (via LlamaIndex)

# Anthropic via LlamaIndex (recommended)
LLM_PROVIDER="llama_index.llms.anthropic.Anthropic"
LLM_API_KEY="<your-anthropic-key>"
LLM_BASE_URL="https://api.anthropic.com"
LL_MODEL="claude-sonnet-4-5"
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=8000

# Alternative: OpenAI via LlamaIndex
# LLM_PROVIDER="llama_index.llms.openai.OpenAI"
# LLM_API_KEY="<your-openai-key>"
# LLM_BASE_URL=""
# LL_MODEL="gpt-4o"

# Alternative: OpenAI-compatible endpoint via LlamaIndex
# LLM_PROVIDER="llama_index.llms.openai_like.OpenAILike"
# LLM_BASE_URL="<your-openai-compatible-endpoint>"
# LLM_API_KEY="<api_key>"
# LL_MODEL="<model-name>"

# =============================================================================
# EMBEDDING CONFIGURATION
# =============================================================================
# The embedding provider generates vectors for CV-to-job matching/scoring.
# Choose ONE of the following options:

# -----------------------------------------------------------------------------
# Option 1: Ollama (FREE, local, requires Ollama installed)
# -----------------------------------------------------------------------------
# Best for: Production use with good semantic matching
# Requires: Install Ollama (brew install ollama), then: ollama pull nomic-embed-text
# 
EMBEDDING_PROVIDER="ollama"
EMBEDDING_MODEL="nomic-embed-text"
EMBEDDING_API_KEY=""
EMBEDDING_BASE_URL=""

# -----------------------------------------------------------------------------
# Option 2: Local TF-IDF (FREE, no external dependencies)
# -----------------------------------------------------------------------------
# Best for: Quick development/testing, or when Ollama isn't available
# Trade-off: Less semantically rich than neural embeddings
#
# EMBEDDING_PROVIDER="local_tfidf"
# EMBEDDING_MODEL=""
# EMBEDDING_API_KEY=""
# EMBEDDING_BASE_URL=""

# -----------------------------------------------------------------------------
# Option 3: OpenAI Embeddings (PAID, cloud API)
# -----------------------------------------------------------------------------
# Best for: Production use with high-quality semantic matching
# Requires: OpenAI API key with embedding access
#
# EMBEDDING_PROVIDER="openai"
# EMBEDDING_MODEL="text-embedding-3-small"
# EMBEDDING_API_KEY="<your-openai-key>"
# EMBEDDING_BASE_URL=""

# =============================================================================
# VENDOR KEY BACKFILL (optional)
# =============================================================================
# If you prefer, you can set vendor-specific keys and leave LLM_API_KEY empty.
# The system will automatically use the appropriate vendor key.
#
# ANTHROPIC_API_KEY="<your-anthropic-key>"
# OPENAI_API_KEY="<your-openai-key>"
# RAYCAST_API_KEY="<your-raycast-key>"
